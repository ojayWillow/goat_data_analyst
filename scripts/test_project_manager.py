#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Enterprise ProjectManager Test - V2 Enhanced.

Tests the upgraded ProjectManager with:
- Worker-based architecture
- Deep code analysis
- Architecture validation
- Dependency mapping
- Comprehensive health reporting
- Actual test case counting (not just test files)

Run: python scripts/test_project_manager.py
"""

import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agents.project_manager.project_manager import ProjectManager


def print_header(title):
    """Print formatted header."""
    print(f"\n{'='*70}")
    print(f"  {title}")
    print(f"{'='*70}")


def test_project_manager():
    """Test ProjectManager V2."""
    print_header("ğŸ’¬ ProjectManager V2 - Enterprise-Grade Project Coordinator")
    
    try:
        # Initialize
        print("\nğŸš€ Initializing ProjectManager...")
        pm = ProjectManager()
        print("   âœ… Initialized successfully")
        
        # Execute full analysis
        print("\nğŸ“Š Executing complete project analysis...")
        report = pm.execute()
        print("   âœ… Analysis complete")
        
        # ===== STRUCTURE ANALYSIS ====="
        print_header("ğŸ“‹ DISCOVERED STRUCTURE")
        structure = report["structure"]
        
        print(f"\nğŸ“„ Agents Discovered: {len(structure['agents'])}")
        for agent_name, info in structure["agents"].items():
            workers = f" [{info.get('worker_count', 0)} workers]" if info.get("has_workers") else ""
            test_status = "âœ… Has test" if info.get("has_test") else "âš ï¸  No test"
            size_kb = info.get("file_size_bytes", 0) / 1024
            print(f"   â€¢ {agent_name:<20} {test_status:<15} {size_kb:>6.1f}KB{workers}")
        
        print(f"\nğŸ“‹ Core Systems: {len(structure['core_systems'])}")
        for system_name in list(structure["core_systems"].keys()):
            size_kb = structure["core_systems"][system_name].get("file_size_bytes", 0) / 1024
            print(f"   â€¢ {system_name:<25} {size_kb:>6.1f}KB")
        
        print(f"\nğŸ“‹ Documentation: {len(structure['documentation'])} files")
        for doc_name in list(structure["documentation"].keys())[:5]:
            print(f"   â€¢ {doc_name}")
        if len(structure["documentation"]) > 5:
            print(f"   ... and {len(structure['documentation']) - 5} more")
        
        # ===== PATTERNS ====="
        print_header("ğŸ§  LEARNED PATTERNS")
        patterns = report["patterns"]
        
        print(f"\nğŸ“„ Pattern Confidence: {patterns['pattern_confidence']*100:.0f}%")
        print(f"   Agents Analyzed: {patterns['total_agents_analyzed']}")
        
        print(f"\nğŸ“„ Naming Conventions:")
        for convention, value in patterns.get("naming_conventions", {}).items():
            print(f"   â€¢ {convention}: {value}")
        
        # ===== CODE ANALYSIS ====="
        print_header("ğŸ“ CODE ANALYSIS")
        code_analysis = report.get("code_analysis", {})
        
        if code_analysis:
            type_hints = [a.get("type_hints_coverage", 0) for a in code_analysis.values()]
            docstrings = [a.get("docstring_coverage", 0) for a in code_analysis.values()]
            avg_complexity = [a.get("complexity_score", 0) for a in code_analysis.values()]
            
            print(f"\nğŸ“„ Coverage Metrics:")
            print(f"   â€¢ Avg Type Hints: {sum(type_hints)/len(type_hints) if type_hints else 0:.1f}%")
            print(f"   â€¢ Avg Docstrings: {sum(docstrings)/len(docstrings) if docstrings else 0:.1f}%")
            print(f"   â€¢ Avg Complexity: {sum(avg_complexity)/len(avg_complexity) if avg_complexity else 0:.1f}/10")
            
            # Show worst performers
            sorted_hints = sorted(code_analysis.items(), 
                                 key=lambda x: x[1].get("type_hints_coverage", 0))
            if sorted_hints and sorted_hints[0][1].get("type_hints_coverage", 0) < 100:
                print(f"\nğŸ“„ Needs Type Hints:")
                for agent_name, analysis in sorted_hints[:3]:
                    print(f"   â€¢ {agent_name}: {analysis.get('type_hints_coverage', 0):.0f}%")
        
        # ===== ARCHITECTURE ====="
        print_header("ğŸ—ï¸  ARCHITECTURE VALIDATION")
        architecture = report.get("architecture", {})
        
        if architecture:
            print(f"\nğŸ“„ Architecture Score: {architecture.get('overall_score', 0):.1f}/100")
            print(f"   â€¢ Well-structured: {architecture.get('well_structured', 0)}/{architecture.get('total_agents', 0)}")
            
            if architecture.get("issues"):
                print(f"\nğŸ“„ Issues Found:")
                for issue in architecture.get("issues", [])[:5]:
                    print(f"   âš ï¸  {issue}")
            
            if architecture.get("recommendations"):
                print(f"\nğŸ“„ Recommendations:")
                for rec in architecture.get("recommendations", [])[:5]:
                    print(f"   â€¢ {rec}")
        
        # ===== DEPENDENCIES ====="
        print_header("ğŸ—ºï¸  DEPENDENCY ANALYSIS")
        dependencies = report.get("dependencies", {})
        
        if dependencies:
            print(f"\nğŸ“„ External Dependencies: {dependencies.get('total_external', 0)}")
            external = dependencies.get("external_dependencies", [])
            for dep in sorted(external)[:10]:
                print(f"   â€¢ {dep}")
            if len(external) > 10:
                print(f"   ... and {len(external) - 10} more")
        
        # ===== HEALTH REPORT ====="
        print_header("ğŸ’  PROJECT HEALTH")
        health = report["health"]
        
        print(f"\nğŸ“„ Health Score: {health['health_score']}/100 - {health['status']}")
        
        summary = health["summary"]
        print(f"\nğŸ“„ Summary:")
        print(f"   â€¢ Total Agents: {summary['total_agents']}")
        print(f"   â€¢ Tested: {summary['tested_agents']}")
        print(f"   â€¢ Untested: {summary['untested_agents']}")
        print(f"   â€¢ Test Coverage: {summary['test_coverage']:.1f}%")
        print(f"   â€¢ Total Test Files: {summary['total_tests']}")
        print(f"   â€¢ Total Test Cases: {summary.get('total_test_cases', 'N/A')}")
        print(f"   â€¢ With Workers: {summary['agents_with_workers']}")
        
        # ===== CHANGES ====="
        print_header("ğŸ“ CHANGE TRACKING")
        changes = report["changes"]
        
        print(f"\nğŸ“„ Changes Detected:")
        if changes.get("new_agents"):
            print(f"   âœ… New agents: {', '.join(changes['new_agents'])}")
        if changes.get("removed_agents"):
            print(f"   ğŸ—‘ï¸  Removed agents: {', '.join(changes['removed_agents'])}")
        if changes.get("new_tests"):
            print(f"   ğŸ“‹ New tests: {', '.join(changes['new_tests'])}")
        
        if not (changes.get("new_agents") or changes.get("new_tests") or changes.get("removed_agents")):
            print(f"   âœ… No changes detected (stable state)")
        
        # ===== VALIDATION ====="
        print_header("ğŸ‘ AGENT VALIDATION")
        test_agents = ["new_agent", "test_agent", "DataLoader", ""]
        for test_name in test_agents:
            validation = pm.validate_new_agent(test_name)
            status = "âœ…" if validation["valid"] else "âš ï¸ "
            issues = f" ({', '.join(validation['issues'][:1])" if validation["issues"] else ""
            print(f"\n   {test_name or '(empty)':<20} {status}")
            if issues:
                print(f"   {issues})")
        
        # ===== SUMMARY ====="
        print_header("âœ… TEST RESULTS")
        print(f"""
ProjectManager V2 - Enterprise Features:
ğŸ“„ Auto-Discovery      âœ…
ğŸ§  Pattern Learning    âœ…
ğŸ“ Code Analysis      âœ…
ğŸ—ï¸  Architecture Check âœ…
ğŸ—ºï¸  Dependency Map     âœ…
ğŸ“ Change Tracking   âœ…
ğŸ’  Health Reporting   âœ…
ğŸ‘ Validation         âœ…
""")
        
        # Print full health report
        print("\n" + "="*70)
        pm.print_report()
        print("="*70)
        
        print(f"""
ğŸš€ ProjectManager V2 is fully operational!

âœ¨ What's New:
   â€¢ 8 specialized workers (single responsibility)
   â€¢ Deep AST-based code analysis
   â€¢ Architecture pattern validation
   â€¢ External dependency mapping
   â€¢ Advanced health metrics
   â€¢ Worker subfolder detection
   â€¢ Type hints & docstring coverage
   â€¢ Complexity scoring
   â€¢ Actual test case counting (AST-based)

Ready for Week 1 hardening testing phase! ğŸ“Š
""")
        
        return True
        
    except Exception as e:
        print_header("âŒ ERROR")
        print(f"\nError: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_project_manager()
    sys.exit(0 if success else 1)
